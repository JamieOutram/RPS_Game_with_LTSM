{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Lib.RPS_game import DELETE_ABBEY, play, mrugesh, abbey, quincy, kris, human, random_player\n",
    "from Lib.RPS_encoding import RPS_encode, RPS_decode\n",
    "from Lib.Telepathic_player import telepath\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import random\n",
    "import itertools\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability import distributions as tfd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_len = 1000\n",
    "batch_size = 100\n",
    "order = 2\n",
    "keys = ['0', '1', '2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "## Reading Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Opponent</th>\n",
       "      <th>Result</th>\n",
       "      <th>Winning_Play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P</td>\n",
       "      <td>P</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P</td>\n",
       "      <td>P</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P</td>\n",
       "      <td>P</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S</td>\n",
       "      <td>P</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Player Opponent Result Winning_Play\n",
       "0      P        P      0            S\n",
       "1      P        P      0            S\n",
       "2      R        S      1            R\n",
       "3      P        P      0            S\n",
       "4      S        P      1            S"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"Games/\"\n",
    "all_game_paths = [join(path, f) for f in listdir(path) if isfile(join(path, f))]\n",
    "games_concat = pd.DataFrame(columns = [\"Player\",\"Opponent\",\"Result\",\"Winning_Play\"])\n",
    "games = []\n",
    "for game_path in all_game_paths:\n",
    "    #print(game_path)\n",
    "    game_data = pd.read_csv(game_path, names = [\"Player\",\"Opponent\",\"Result\",\"Winning_Play\"])\n",
    "    games.append(game_data)\n",
    "    games_concat = games_concat.append(game_data)\n",
    "    \n",
    "#print(len(game_data.index)) \n",
    "#game_data.head()  \n",
    "print(len(games_concat.index))\n",
    "games_concat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "Calculate the freqeuncy of past plays from each state and prepare for input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120000\n",
      "        Prev_Play_0  Prev_Play_1  Prev_Play_2   00   01   02   10   11   12  \\\n",
      "0                 0            1            0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
      "1                 0            1            0  0.0  1.0  0.0  0.0  1.0  0.0   \n",
      "2                 1            0            0  0.0  1.0  0.0  1.0  1.0  0.0   \n",
      "3                 0            1            0  0.0  1.0  0.0  1.0  1.0  0.0   \n",
      "4                 0            0            1  0.0  1.0  0.0  0.0  0.0  0.0   \n",
      "...             ...          ...          ...  ...  ...  ...  ...  ...  ...   \n",
      "119995            0            0            1  0.0  0.0  0.0  1.0  1.0  0.0   \n",
      "119996            0            0            1  0.0  0.0  0.0  1.0  1.0  0.0   \n",
      "119997            0            1            0  0.0  0.0  0.0  1.0  1.0  0.0   \n",
      "119998            0            0            1  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "119999            1            0            0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "         20   21   22  \n",
      "0       0.0  0.0  0.0  \n",
      "1       0.0  0.0  0.0  \n",
      "2       0.0  0.0  0.0  \n",
      "3       0.0  0.0  0.0  \n",
      "4       0.0  0.0  0.0  \n",
      "...     ...  ...  ...  \n",
      "119995  1.0  0.0  0.0  \n",
      "119996  1.0  0.0  1.0  \n",
      "119997  0.0  0.0  0.0  \n",
      "119998  0.0  0.0  0.0  \n",
      "119999  1.0  0.0  0.0  \n",
      "\n",
      "[120000 rows x 12 columns]\n",
      "0         2\n",
      "1         2\n",
      "2         0\n",
      "3         2\n",
      "4         2\n",
      "         ..\n",
      "119995    2\n",
      "119996    2\n",
      "119997    1\n",
      "119998    2\n",
      "119999    0\n",
      "Length: 120000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def grouper(iterable, n, fillvalue=None):\n",
    "    args = [iter(iterable)] * n\n",
    "    return itertools.zip_longest(*args, fillvalue=fillvalue)\n",
    "\n",
    "def create_states(count):            \n",
    "    states = []\n",
    "    for i in itertools.product(keys, repeat=count):\n",
    "        states.append(''.join(i))\n",
    "    return states\n",
    "\n",
    "def get_dist(array, order):\n",
    "    patterns = create_states(order)\n",
    "    dist = {pat : 0 for pat in patterns}\n",
    "    rolling_pattern = patterns[0]\n",
    "    for play in array:\n",
    "        rolling_pattern = rolling_pattern[1:] + str(play)\n",
    "        dist[rolling_pattern] += 1\n",
    "    return dist\n",
    "\n",
    "def normalise_dist(dist):\n",
    "    #look at all possible next states from each pattern and group\n",
    "    #for each group subtract minimum count from total \n",
    "    groups = [[''.join(pat) + key for key in keys] for pat in itertools.product(keys, repeat=order-1)]\n",
    "    for group in groups:\n",
    "        counts = [dist[key] for key in group]\n",
    "        #Normalize group between 0-1\n",
    "        for key in group:\n",
    "            if(max(counts)==min(counts)):\n",
    "                dist[key] = 0\n",
    "            else:\n",
    "                dist[key] = (dist[key]-min(counts))/(max(counts)-min(counts))            \n",
    "    \n",
    "    return list(dist.values())\n",
    "\n",
    "def get_all_normalised_dist(array, order):\n",
    "    all_dist = []\n",
    "    patterns = create_states(order)\n",
    "    dist = {pat : 0 for pat in patterns}\n",
    "    rolling_pattern = patterns[0]\n",
    "    for play in array:\n",
    "        rolling_pattern = rolling_pattern[1:] + str(play)\n",
    "        dist[rolling_pattern] += 1\n",
    "        all_dist.append(list(normalise_dist(dist)))\n",
    "    return all_dist\n",
    "\n",
    "def prep_input(prev_play, dist):\n",
    "    return [prev_play] + dist\n",
    "    \n",
    "temp = games_concat.drop(\"Result\", axis = 1)\n",
    "temp.index = [x for x in range(temp.index.size)]\n",
    "\n",
    "#handling feature engineering in pandas\n",
    "player_input = [RPS_encode(x) for x in temp.loc[:,\"Player\"]]\n",
    "winning_plays = [RPS_encode(x) for x in temp.loc[:,\"Winning_Play\"]]\n",
    "#past player play distribution:\n",
    "\n",
    "\n",
    "patterns = create_states(order)\n",
    "all_dists = []\n",
    "#-every 1000 entries reset distribution (simulates multiple games)\n",
    "for game in grouper(player_input, game_len, fillvalue=0):\n",
    "    all_dists += get_all_normalised_dist(game, order)\n",
    "        \n",
    "print(len(all_dists))\n",
    "#print(all_dists[0:5])\n",
    "#print(all_dists[998:1003])  \n",
    "input_dataframe = pd.DataFrame(all_dists, columns = patterns)\n",
    "input_dataframe = pd.concat([pd.get_dummies(player_input, prefix = 'Prev_Play'), input_dataframe], axis=1)\n",
    "#input_dataframe.drop(input_dataframe.tail(1).index, inplace=True)\n",
    "print(input_dataframe)\n",
    "\n",
    "target_series = pd.Series(winning_plays)\n",
    "#target_series.drop(target_series.head(1).index, inplace=True)\n",
    "#target_series.index = [x for x in range(len(input_dataframe))]\n",
    "print(target_series)\n",
    "\n",
    "    \n",
    "#tempInput = [ for prev_play, dist in zip(player_input, all_dists)]\n",
    "#tempTarget = [RPS_encode(x) for x in temp.loc[:,\"Winning_Play\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert pandas DataFrame to tensorflow Dataset, batch inputs and offset targets and inputs so the input predicts the next target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = tf.data.Dataset.from_tensor_slices(input_dataframe)\n",
    "target_data = tf.data.Dataset.from_tensor_slices(target_series)\n",
    "\n",
    "\n",
    "#split into training batches\n",
    "input_batches = input_data.batch(batch_size+1, drop_remainder = True)\n",
    "target_batches = target_data.batch(batch_size+1, drop_remainder = True)\n",
    "\n",
    "#When predicting based off player inputs need to shift targets one time step\n",
    "#remove last element from all input sequences\n",
    "def remove_last(chunk):\n",
    "    return chunk[:-1]\n",
    "input_batches = input_batches.map(remove_last)\n",
    "\n",
    "#remove first element from all target sequences\n",
    "def remove_first(chunk):\n",
    "    return chunk[1:]\n",
    "target_batches = target_batches.map(remove_first)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine input and target batches then split the dataset into training, test and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sequence count: 1188\n",
      "Training set: 831\n",
      "Test set: 179\n",
      "Validation set: 178\n",
      "[[0.         0.         1.         0.         1.         0.5\n",
      "  0.         0.55555556 1.         0.         1.         1.        ]\n",
      " [0.         0.         1.         0.         1.         0.5\n",
      "  0.         0.55555556 1.         0.         0.5        1.        ]\n",
      " [0.         1.         0.         0.         1.         0.5\n",
      "  0.         0.55555556 1.         0.         1.         0.66666667]\n",
      " [0.         1.         0.         0.         1.         0.5\n",
      "  0.         1.         0.64285714 0.         1.         0.66666667]\n",
      " [0.         0.         1.         0.         1.         0.5\n",
      "  0.         0.60869565 1.         0.         1.         0.66666667]]\n",
      "[1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "full_dataset = tf.data.Dataset.zip((input_batches, target_batches)).shuffle(10000)\n",
    "\n",
    "dataset_size = len(full_dataset)\n",
    "train_size = int(0.7*dataset_size)\n",
    "test_size = int(0.15*dataset_size)\n",
    "val_size = int(0.15*dataset_size)\n",
    "\n",
    "train_dataset = full_dataset.take(train_size)\n",
    "test_dataset = full_dataset.skip(train_size)\n",
    "val_dataset = test_dataset.take(test_size)\n",
    "test_dataset = test_dataset.skip(test_size)\n",
    "\n",
    "print(\"Total sequence count: \" + str(dataset_size))\n",
    "print(\"Training set: \" + str(len(train_dataset)))\n",
    "print(\"Test set: \" + str(len(test_dataset)))\n",
    "print(\"Validation set: \" + str(len(val_dataset)))\n",
    "for x , y in train_dataset.take(1):\n",
    "    print(x.numpy()[0:5])\n",
    "    print(y.numpy()[0:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (100, 64)                 832       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (100, 12)                 780       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (100, 3)                  39        \n",
      "=================================================================\n",
      "Total params: 1,651\n",
      "Trainable params: 1,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(input_dims, vocab_size, batch_size):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.InputLayer(batch_input_shape = [batch_size, input_dims]))\n",
    "    model.add(Dense(64, activation = 'relu'))\n",
    "    model.add(Dense(12, activation = 'relu'))\n",
    "    model.add(Dense(vocab_size, activation = 'softmax'))\n",
    "    return model\n",
    "vocab_size = len(keys)\n",
    "model = build_model(len(patterns)+vocab_size, vocab_size, batch_size)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TakeDataset shapes: ((100, 12), (100,)), types: (tf.float64, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "831/831 [==============================] - 3s 2ms/step - loss: 0.7962 - accuracy: 0.6539\n",
      "Epoch 2/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.6449 - accuracy: 0.7337\n",
      "Epoch 3/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.6145 - accuracy: 0.7430\n",
      "Epoch 4/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.6007 - accuracy: 0.7416\n",
      "Epoch 5/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5880 - accuracy: 0.7478\n",
      "Epoch 6/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5776 - accuracy: 0.7484\n",
      "Epoch 7/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5641 - accuracy: 0.7507\n",
      "Epoch 8/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5702 - accuracy: 0.7503\n",
      "Epoch 9/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5544 - accuracy: 0.7554\n",
      "Epoch 10/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5653 - accuracy: 0.7497\n",
      "Epoch 11/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5642 - accuracy: 0.7510\n",
      "Epoch 12/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5512 - accuracy: 0.7585\n",
      "Epoch 13/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5584 - accuracy: 0.7529\n",
      "Epoch 14/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5379 - accuracy: 0.7642\n",
      "Epoch 15/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5468 - accuracy: 0.7581\n",
      "Epoch 16/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5350 - accuracy: 0.7612\n",
      "Epoch 17/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5353 - accuracy: 0.7623\n",
      "Epoch 18/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5499 - accuracy: 0.7541\n",
      "Epoch 19/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5295 - accuracy: 0.7604\n",
      "Epoch 20/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5396 - accuracy: 0.7585\n",
      "Epoch 21/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5259 - accuracy: 0.7697\n",
      "Epoch 22/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5377 - accuracy: 0.7604\n",
      "Epoch 23/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5344 - accuracy: 0.7649\n",
      "Epoch 24/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5339 - accuracy: 0.7619\n",
      "Epoch 25/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5462 - accuracy: 0.7543\n",
      "Epoch 26/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5242 - accuracy: 0.7645\n",
      "Epoch 27/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5286 - accuracy: 0.7644\n",
      "Epoch 28/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5369 - accuracy: 0.7601\n",
      "Epoch 29/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5359 - accuracy: 0.7574\n",
      "Epoch 30/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5398 - accuracy: 0.7552\n",
      "Epoch 31/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5341 - accuracy: 0.7609\n",
      "Epoch 32/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5370 - accuracy: 0.7561\n",
      "Epoch 33/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5273 - accuracy: 0.7627\n",
      "Epoch 34/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5186 - accuracy: 0.7681\n",
      "Epoch 35/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5283 - accuracy: 0.7618\n",
      "Epoch 36/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5436 - accuracy: 0.7569\n",
      "Epoch 37/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5327 - accuracy: 0.7619\n",
      "Epoch 38/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5360 - accuracy: 0.7578\n",
      "Epoch 39/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5276 - accuracy: 0.7637\n",
      "Epoch 40/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5406 - accuracy: 0.7578\n",
      "Epoch 41/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5271 - accuracy: 0.7616\n",
      "Epoch 42/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5276 - accuracy: 0.7595\n",
      "Epoch 43/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5283 - accuracy: 0.7613\n",
      "Epoch 44/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5206 - accuracy: 0.7668\n",
      "Epoch 45/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5354 - accuracy: 0.7605\n",
      "Epoch 46/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5302 - accuracy: 0.7617\n",
      "Epoch 47/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5323 - accuracy: 0.7596\n",
      "Epoch 48/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5189 - accuracy: 0.7645\n",
      "Epoch 49/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5303 - accuracy: 0.7607\n",
      "Epoch 50/50\n",
      "831/831 [==============================] - 2s 2ms/step - loss: 0.5190 - accuracy: 0.7684\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d5d392a520>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179/179 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7711\n",
      "Test accuracy: 0.7710614800453186\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset,verbose = 1)\n",
    "print('Test accuracy: ' + str(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.28083214, 0.39425772, 0.32491016]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_input = [0 for x in range(len(patterns)+vocab_size)]\n",
    "testing_input[0] = 1\n",
    "model.predict([testing_input])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save or Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Models/DNN_PlayerPastInputFrequency\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('Models/DNN_PlayerPastInputFrequency_Abbey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (100, 64)                 832       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (100, 12)                 780       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (100, 3)                  39        \n",
      "=================================================================\n",
      "Total params: 1,651\n",
      "Trainable params: 1,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('Models/DNN_PlayerPastInputFrequency_Abbey') \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model\n",
    "\n",
    "Define functions to interface between the game and the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Prediction(model, player_history):\n",
    "    #format history for input\n",
    "    input_eval = [RPS_encode(c) for c in player_history]\n",
    "    input_eval = get_dist(input_eval, order)\n",
    "    input_eval = normalise_dist(input_eval)\n",
    "    RPS = {'R':[1,0,0],'P':[0,1,0],'S':[0,0,1]}\n",
    "    input_eval = RPS[player_history[-1]] + input_eval\n",
    "    \n",
    "    #print(input_eval)\n",
    "    \n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    \n",
    "    #high temperature  => suprising output\n",
    "    #low temperature => predictable output\n",
    "    temperature = 0.1; \n",
    "    \n",
    "    model.reset_states()\n",
    "    \n",
    "    prediction = model(input_eval)\n",
    "    #prediction = tf.squeeze(prediction, 0)\n",
    "    \n",
    "    prediction = prediction / temperature\n",
    "    #print(prediction)\n",
    "    predicted_id = tf.random.categorical(prediction, num_samples = 1)[-1,0].numpy()\n",
    "    #print(predicted_id)\n",
    "    #print(\"Guessing: \" + RPSpair_decode(predicted_id))\n",
    "    return RPS_decode(predicted_id)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plays = 1000\n",
    "\n",
    "def DELETE_PLAYER():\n",
    "    player('', isClear = True)\n",
    "\n",
    "def player(prev_play, opponent_history = [], play_history=['R'], isClear = False):\n",
    "    if isClear: \n",
    "        opponent_history.clear()\n",
    "        play_history.clear()\n",
    "        play_history.append('R')\n",
    "        return\n",
    "    \n",
    "    opponent_history.append(prev_play)\n",
    "    #print(\"Actual: \" + prev_play) \n",
    "    guess = Get_Prediction(model, play_history)\n",
    "    #print(guess)\n",
    "    play_history.append(guess)\n",
    "    return guess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play RPS games\n",
    "Clears player's and abbey's memory before each run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results: {'p1': 785, 'p2': 61, 'tie': 154}\n",
      "Player 1 win rate: 92.78959810874704%\n",
      "Final results: {'p1': 723, 'p2': 112, 'tie': 165}\n",
      "Player 1 win rate: 86.58682634730539%\n",
      "Final results: {'p1': 714, 'p2': 112, 'tie': 174}\n",
      "Player 1 win rate: 86.4406779661017%\n",
      "Final results: {'p1': 720, 'p2': 111, 'tie': 169}\n",
      "Player 1 win rate: 86.64259927797833%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "86.64259927797833"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DELETE_PLAYER()\n",
    "DELETE_ABBEY()\n",
    "play(player, abbey, plays)\n",
    "DELETE_PLAYER()\n",
    "DELETE_ABBEY()\n",
    "play(player, abbey, plays)\n",
    "DELETE_PLAYER()\n",
    "DELETE_ABBEY()\n",
    "play(player, abbey, plays)\n",
    "DELETE_PLAYER()\n",
    "DELETE_ABBEY()\n",
    "play(player, abbey, plays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
