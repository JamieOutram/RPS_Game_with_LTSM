{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "### Players from RPS_game.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def play(player1, player2, num_games, verbose=False):\n",
    "    p1_prev_play = \"\"\n",
    "    p2_prev_play = \"\"\n",
    "    results = {\"p1\": 0, \"p2\": 0, \"tie\": 0}\n",
    "\n",
    "    for _ in range(num_games):\n",
    "        p1_play = player1(p2_prev_play)\n",
    "        p2_play = player2(p1_prev_play)\n",
    "\n",
    "        if p1_play == p2_play:\n",
    "            results[\"tie\"] += 1\n",
    "            winner = \"Tie.\"\n",
    "        elif (p1_play == \"P\" and p2_play == \"R\") or (\n",
    "                p1_play == \"R\" and p2_play == \"S\") or (p1_play == \"S\"\n",
    "                                                       and p2_play == \"P\"):\n",
    "            results[\"p1\"] += 1\n",
    "            winner = \"Player 1 wins.\"\n",
    "        elif p2_play == \"P\" and p1_play == \"R\" or p2_play == \"R\" and p1_play == \"S\" or p2_play == \"S\" and p1_play == \"P\":\n",
    "            results[\"p2\"] += 1\n",
    "            winner = \"Player 2 wins.\"\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Player 1:\", p1_play, \"| Player 2:\", p2_play)\n",
    "            print(winner)\n",
    "            print()\n",
    "\n",
    "        p1_prev_play = p1_play\n",
    "        p2_prev_play = p2_play\n",
    "\n",
    "    games_won = results['p2'] + results['p1']\n",
    "\n",
    "    if games_won == 0:\n",
    "        win_rate = 0\n",
    "    else:\n",
    "        win_rate = results['p1'] / games_won * 100\n",
    "\n",
    "    print(\"Final results:\", results)\n",
    "    print(f\"Player 1 win rate: {win_rate}%\")\n",
    "\n",
    "    return (win_rate)\n",
    "\n",
    "\n",
    "def quincy(prev_play, counter=[0]):\n",
    "\n",
    "    counter[0] += 1\n",
    "    choices = [\"R\", \"R\", \"P\", \"P\", \"S\"]\n",
    "    return choices[counter[0] % len(choices)]\n",
    "\n",
    "\n",
    "def mrugesh(prev_opponent_play, opponent_history=[]):\n",
    "    opponent_history.append(prev_opponent_play)\n",
    "    last_ten = opponent_history[-10:]\n",
    "    most_frequent = max(set(last_ten), key=last_ten.count)\n",
    "\n",
    "    if most_frequent == '':\n",
    "        most_frequent = \"S\"\n",
    "\n",
    "    ideal_response = {'P': 'S', 'R': 'P', 'S': 'R'}\n",
    "    return ideal_response[most_frequent]\n",
    "\n",
    "\n",
    "def kris(prev_opponent_play):\n",
    "    if prev_opponent_play == '':\n",
    "        prev_opponent_play = \"R\"\n",
    "    ideal_response = {'P': 'S', 'R': 'P', 'S': 'R'}\n",
    "    return ideal_response[prev_opponent_play]\n",
    "\n",
    "\n",
    "def abbey(prev_opponent_play,\n",
    "          opponent_history=[],\n",
    "          play_order=[{\n",
    "              \"RR\": 0,\n",
    "              \"RP\": 0,\n",
    "              \"RS\": 0,\n",
    "              \"PR\": 0,\n",
    "              \"PP\": 0,\n",
    "              \"PS\": 0,\n",
    "              \"SR\": 0,\n",
    "              \"SP\": 0,\n",
    "              \"SS\": 0,\n",
    "          }]):\n",
    "\n",
    "    if not prev_opponent_play:\n",
    "        prev_opponent_play = 'R'\n",
    "    opponent_history.append(prev_opponent_play)\n",
    "\n",
    "    last_two = \"\".join(opponent_history[-2:])\n",
    "    if len(last_two) == 2:\n",
    "        play_order[0][last_two] += 1\n",
    "\n",
    "    potential_plays = [\n",
    "        prev_opponent_play + \"R\",\n",
    "        prev_opponent_play + \"P\",\n",
    "        prev_opponent_play + \"S\",\n",
    "    ]\n",
    "\n",
    "    sub_order = {\n",
    "        k: play_order[0][k]\n",
    "        for k in potential_plays if k in play_order[0]\n",
    "    }\n",
    "\n",
    "    prediction = max(sub_order, key=sub_order.get)[-1:]\n",
    "\n",
    "    ideal_response = {'P': 'S', 'R': 'P', 'S': 'R'}\n",
    "    return ideal_response[prediction]\n",
    "\n",
    "\n",
    "def human(prev_opponent_play):\n",
    "    play = \"\"\n",
    "    while play not in ['R', 'P', 'S']:\n",
    "        play = input(\"[R]ock, [P]aper, [S]cissors? \")\n",
    "        print(play)\n",
    "    return play\n",
    "\n",
    "\n",
    "def random_player(prev_opponent_play):\n",
    "    return random.choice(['R', 'P', 'S'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data from Players\n",
    "generate 10 games of 1000 from each player with winning response output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateGames(player, opponent, game_count = 10, game_length = 1000, cheater = False):\n",
    "    if(cheater):\n",
    "        player = TelepathicPlayer\n",
    "    \n",
    "    filename = \"Games/\" + player.__name__ + \"_vs_\" + opponent.__name__ + \"_game_\"\n",
    "    for i in range(0 , game_count):\n",
    "        f = open(filename + str(i) + \".txt\", \"w\")\n",
    "        p1_prev_play = \"\"\n",
    "        p2_prev_play = \"\"\n",
    "        for _ in range(game_length):\n",
    "            \n",
    "            p2_play = opponent(p1_prev_play)\n",
    "            if(cheater):\n",
    "                p1_play = player(p2_play)\n",
    "            else:\n",
    "                p1_play = player(p2_prev_play)\n",
    "            player_win = 0\n",
    "            if (p1_play == \"P\" and p2_play == \"R\") or \\\n",
    "                (p1_play == \"R\" and p2_play == \"S\") or \\\n",
    "                (p1_play == \"S\" and p2_play == \"P\"):\n",
    "                player_win = 1\n",
    "            f.write(p1_play + \",\" + p2_play + \",\" + str(player_win) + '\\n')\n",
    "            \n",
    "            p1_prev_play = p1_play\n",
    "            p2_prev_play = p2_play\n",
    "        f.close()\n",
    "        \n",
    "def TelepathicPlayer(opponent_guess):\n",
    "    if(opponent_guess == 'R'):\n",
    "        return 'P'\n",
    "    elif(opponent_guess == 'P'):\n",
    "        return 'S'\n",
    "    elif(opponent_guess == 'S'):\n",
    "        return 'R'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GenerateGames(random_player, quincy)\n",
    "#GenerateGames(random_player, abbey)\n",
    "#GenerateGames(random_player, kris)\n",
    "#GenerateGames(random_player, mrugesh)\n",
    "GenerateGames(TelepathicPlayer, quincy, cheater = True)\n",
    "GenerateGames(TelepathicPlayer, abbey, cheater = True, game_count = 10)\n",
    "GenerateGames(TelepathicPlayer, kris, cheater = True)\n",
    "GenerateGames(TelepathicPlayer, mrugesh, cheater = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and Concatenate Games\n",
    "Take all games and load into dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "path = \"Games/\"\n",
    "all_game_paths = [join(path, f) for f in listdir(path) if isfile(join(path, f))]\n",
    "games_concat = pd.DataFrame(columns = [\"Player\",\"Opponent\",\"Result\"])\n",
    "games = []\n",
    "for game_path in all_game_paths:\n",
    "    #print(game_path)\n",
    "    game_data = pd.read_csv(game_path, names = [\"Player\",\"Opponent\",\"Result\"])\n",
    "    games.append(game_data)\n",
    "    games_concat = games_concat.append(game_data)\n",
    "    \n",
    "#print(len(game_data.index)) \n",
    "#game_data.head()  \n",
    "print(len(games_concat.index))\n",
    "games_concat.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Training\n",
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 100 #how far back the ltsm looks when training\n",
    "#Model parameters\n",
    "BATCH_SIZE = 64\n",
    "VOCAB_SIZE = 3 # RPS\n",
    "EMBEDDING_DIM = 128\n",
    "RNN_UNITS = 512\n",
    "\n",
    "TRAINING_EPOCHS = 100\n",
    "\n",
    "#best so far\n",
    "#100\n",
    "#64\n",
    "#3\n",
    "#128\n",
    "#512\n",
    "#200\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format data for LTSM training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def encode(df):\n",
    "    df = df.replace('R', 0)\n",
    "    df = df.replace('P', 1)\n",
    "    df = df.replace('S', 2)\n",
    "    return df\n",
    "\n",
    "def encodeRPS(char):\n",
    "    if char == 'R':\n",
    "        return 0\n",
    "    elif char == 'P':\n",
    "        return 1\n",
    "    elif char == 'S':\n",
    "        return 2\n",
    "    \n",
    "def decodeRPS(num):\n",
    "    if num == 0:\n",
    "        return 'R'\n",
    "    elif num == 1:\n",
    "        return 'P'\n",
    "    elif num == 2:\n",
    "        return 'S'\n",
    "    \n",
    "temp = games_concat.drop(\"Result\", axis = 1)\n",
    "temp = encode(temp)\n",
    "input_data = tf.data.Dataset.from_tensor_slices(temp[\"Opponent\"])\n",
    "target_data = tf.data.Dataset.from_tensor_slices(temp[\"Player\"])\n",
    "print(temp)\n",
    "print(input_data)\n",
    "\n",
    "#split into sequences\n",
    "input_sequences = input_data.batch(seq_length+1, drop_remainder = True)\n",
    "target_sequences = target_data.batch(seq_length+1, drop_remainder = True)\n",
    "print(input_sequences)\n",
    "\n",
    "#remove last element from all input sequences\n",
    "def remove_last(chunk):\n",
    "    return chunk[:-1]\n",
    "inputs = input_sequences.map(remove_last)\n",
    "\n",
    "#Code for abbey training\n",
    "#inputs = target_sequences.map(remove_last)\n",
    "\n",
    "#remove first element from all target sequences\n",
    "def remove_first(chunk):\n",
    "    return chunk[1:]\n",
    "targets = target_sequences.map(remove_first)\n",
    "\n",
    "dataset = tf.data.Dataset.zip((inputs, targets))\n",
    "for element in dataset:\n",
    "    print(element)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle sequences before batching\n",
    "data = dataset.shuffle(10000).batch(BATCH_SIZE, drop_remainder = True)\n",
    "\n",
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = keras.Sequential()\n",
    "    model.add(Embedding(vocab_size, embedding_dim, batch_input_shape = [batch_size, None]))\n",
    "    model.add(LSTM(rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'))\n",
    "    model.add(Dense(vocab_size+1))\n",
    "    return model\n",
    "\n",
    "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, BATCH_SIZE)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Checkpoints\n",
    "configure the model to create checkpoints as it trains so the model can be reloaded and continue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "\n",
    "checkpoint_prefix = join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = keras.callbacks.ModelCheckpoint(filepath = checkpoint_prefix, save_weights_only = True)\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#Program can crash when training due to tensorflow 2.0 GPU issue\n",
    "\n",
    "history = model.fit(data, epochs = TRAINING_EPOCHS, callbacks = [checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rebuild model for predicting one output rather than a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change config\n",
    "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, batch_size = 1)\n",
    "#load trained weights from checkpoint\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Outputs from Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Prediction(model, opponent_history):\n",
    "    #format history for input\n",
    "    input_eval = [0 if c == '' else encodeRPS(c) for c in opponent_history]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    \n",
    "    #high temperature  => suprising output\n",
    "    #low temperature => predictable output\n",
    "    temperature = 1; \n",
    "    \n",
    "    model.reset_states()\n",
    "    \n",
    "    prediction = model(input_eval)\n",
    "    prediction = tf.squeeze(prediction, 0)\n",
    "    \n",
    "    prediction = prediction / temperature\n",
    "    predicted_id = tf.random.categorical(prediction, num_samples = 1)[-1,0].numpy()\n",
    "    \n",
    "    return decodeRPS(predicted_id)\n",
    "\n",
    "#print(Get_Prediction(model, ['R','R','P']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RPS.py\n",
    "Player function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plays = 1000\n",
    "\n",
    "def player(prev_play, opponent_history=[]):\n",
    "    if len(opponent_history) >= plays: \n",
    "        opponent_history.clear()\n",
    "        \n",
    "    opponent_history.append(prev_play)\n",
    "\n",
    "    guess = Get_Prediction(model, opponent_history)\n",
    "    \n",
    "    return guess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN.PY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play(player, quincy, plays)\n",
    "play(player, abbey, plays)\n",
    "play(player, kris, plays)\n",
    "play(player, mrugesh, plays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Models/General')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python38164bitf7bfa84029d94e559180d01a2a463659"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
